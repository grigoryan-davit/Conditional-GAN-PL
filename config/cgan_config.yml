experiment_name: "summarization-abstractive"
n_epochs: 100
layers_to_freeze: [1, 5] # null for no freezing
lr_D: [5e-5, 2e-4, 1e-3]
lr_G: [5e-5, 2e-4, 1e-3]
pruning_amount: [None, 0.25, 0.5]
batch_size: 8
max_token_len: 512
max_summary_len: 256
training_tricks: {
    stochastic_weight_avg: True,
    gradient_clip: 0, # 0 means no clipping
    precision: 32, # 32 is full precision, 16 is half precision
    autoscale_batchsize: null, # can be "binsearch" or "power"
    find_lr: True,
  }
early_stopping: { patience: 2, stopping_threshold: 0.08 }

train_datadir: "../data/train/"
val_datadir: "../data/val/"
savedir: "../../models/"
